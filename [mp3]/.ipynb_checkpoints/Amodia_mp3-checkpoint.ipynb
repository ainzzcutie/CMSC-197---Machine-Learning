{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ca07c5c-a44d-49e5-a1d9-5d86d20bf44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Standard Libraries #####\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import email\n",
    "import os\n",
    "import string\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "##### For Preprocessing #####\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "##### For Validation of the Model #####\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fb275a-14d1-44b9-b359-ebfd62530291",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c65b794-818b-4a47-aa2d-634984eb4939",
   "metadata": {},
   "source": [
    "#### Separate the dataset into training set for spam, training set for ham, and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4dce9804-1590-487d-b077-4ce3cf8fabf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the data: (37822, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>email_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>../data/000/000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>../data/000/001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>../data/000/002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>../data/000/003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>../data/000/004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label       email_text\n",
       "0   ham  ../data/000/000\n",
       "1  spam  ../data/000/001\n",
       "2  spam  ../data/000/002\n",
       "3   ham  ../data/000/003\n",
       "4  spam  ../data/000/004"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "\n",
    "df = pd.read_csv(\"labels\", sep=' ', names=['label', 'email_text'])\n",
    "print(\"Size of the data:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b07e4526-2746-4215-9165-e7f2bbe224cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "spam    24912\n",
       "ham     12910\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting spam and ham\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fe45d6-4707-43eb-9f41-bceb1e2bbf5f",
   "metadata": {},
   "source": [
    "### Converting labels to binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7b4377a-852b-4b21-b5fe-5a13c69d1fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37822, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>email_text</th>\n",
       "      <th>labeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>../data/000/000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>../data/000/001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>../data/000/002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>../data/000/003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>../data/000/004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label       email_text  labeling\n",
       "0   ham  ../data/000/000         0\n",
       "1  spam  ../data/000/001         1\n",
       "2  spam  ../data/000/002         1\n",
       "3   ham  ../data/000/003         0\n",
       "4  spam  ../data/000/004         1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 represents 'ham' and 1 represents 'spam'\n",
    "df['labeling'] = df.label.map({'ham':0, 'spam':1})\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4bc72e-36de-4478-a1ad-eea670dbfb2b",
   "metadata": {},
   "source": [
    "### Cleaning the body of the emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d3e74d2-c19a-4348-bcbd-45f8782b44c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove words that are irrelevant as well as the alphanumberic characters, and punctuation marks\n",
    "def clean_email(email_body):\n",
    "    email_body = str(email_body).lower()\n",
    "    \n",
    "    # removing all whitespaces\n",
    "    email_body = re.sub(r'\\s+',' ', email_body) # remove whitespaces\n",
    "    \n",
    "    # removing html tags\n",
    "    tags = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    email_body = re.sub(tags, '', email_body)\n",
    "    \n",
    "    # removing escape characters \n",
    "    ansi_escape =re.compile(r'(\\x9B|\\x1B\\[)[0-?]*[ -\\/]*[@-~]')\n",
    "    email_body = ansi_escape.sub('', email_body)\n",
    "    \n",
    "    # remove all characters except alphabets and digits\n",
    "    email_body = re.sub(r'[^A-Za-z0-9]+', ' ', email_body)\n",
    "    \n",
    "    # remove digits\n",
    "    email_body = re.sub(r'[0-9]',' ',email_body)\n",
    "    \n",
    "    # load stop_words and store the words in a dictionary for faster performance\n",
    "    stop_words = pd.read_csv(\"stop_words.txt\")\n",
    "    with open('stop_words.txt', \"r\") as w:\n",
    "        stopwords_dict = Counter(w.read().split())\n",
    "    \n",
    "    # Remove stop words / meaningless words from the email body\n",
    "    clean_body = ' '.join([word for word in email_body.split() if word not in stopwords_dict])    \n",
    "   \n",
    "    return clean_body"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2061eb-9689-45d6-aa0e-ba614997ecc8",
   "metadata": {},
   "source": [
    "### Getting the message from the emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a8e7c889-bcbf-42cf-ba26-49a5e6523b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"data\"\n",
    "target_list = []\n",
    "i = 0\n",
    "\n",
    "for root, d_names, f_names in os.walk(directory):\n",
    "    for file in f_names:\n",
    "        # make path\n",
    "        file_path = os.path.join(root, file)\n",
    "        \n",
    "        with open(file_path, 'rb') as f:\n",
    "            # Parse the email message\n",
    "            msg = email.message_from_binary_file(f)\n",
    "            body = \"\"\n",
    "            \n",
    "            # Extract the body of the email\n",
    "            if msg.is_multipart():\n",
    "                for payload in msg.get_payload():\n",
    "                    body = payload.get_payload()\n",
    "            # if it is not multipart, immediately get the message\n",
    "            else:\n",
    "                body = msg.get_payload()\n",
    "            \n",
    "            # Clean the email body\n",
    "            cleaned_body = clean_email(body)\n",
    "            if i != 0:\n",
    "                target_list.append(cleaned_body)\n",
    "            else:\n",
    "                i+=1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec0a4e11-6fed-4b14-873c-ee67052feb22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>email_text</th>\n",
       "      <th>labeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>mailing list queried weeks ago running set arc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>luxury watches buy rolex rolex cartier bvlgari...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>academic qualifications prestigious acc redite...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>greetings verify subscription plan fans list c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>guyton sheena will help mortgage loan loan see...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>quiet quiet well straw poll plan running</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>working departed totally bell labs recommended...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spam</td>\n",
       "      <td>nbc today body diet beaches magazines hollywoo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>oil sector going crazy weekly gift kkpt thing ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>magic perfect weekends http othxu rzfzwiwwfoeh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                         email_text  labeling\n",
       "0   ham  mailing list queried weeks ago running set arc...         0\n",
       "1  spam  luxury watches buy rolex rolex cartier bvlgari...         1\n",
       "2  spam  academic qualifications prestigious acc redite...         1\n",
       "3   ham  greetings verify subscription plan fans list c...         0\n",
       "4  spam  guyton sheena will help mortgage loan loan see...         1\n",
       "5   ham           quiet quiet well straw poll plan running         0\n",
       "6   ham  working departed totally bell labs recommended...         0\n",
       "7  spam  nbc today body diet beaches magazines hollywoo...         1\n",
       "8  spam  oil sector going crazy weekly gift kkpt thing ...         1\n",
       "9  spam  magic perfect weekends http othxu rzfzwiwwfoeh...         1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['email_text'] = target_list\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdbb8d6-0c1e-41f1-8b57-ab3894bab005",
   "metadata": {},
   "source": [
    "### Split the dataset into three groups: training set for ham, training set for spam, and the testing set\r",
    "#### \n",
    "Train set: Folders 0-70 (55%); Test set 71-127(45%)\r",
    "#### \n",
    "\r\n",
    "Train sets included 21, 300 emails and 16, 522 emails for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51127781-16a3-44b4-ad71-884a6a05d482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into three groups: training set for ham, training set for spam, and the testing set\n",
    "\n",
    "# Splitting the dataset into a training and testing set first\n",
    "train_set = df[:21300]\n",
    "test_set = df[21300:]\n",
    "\n",
    "# group by label: spam or ham \n",
    "group_train = train_set.groupby('label')\n",
    "# training set for ham, training set for spam\n",
    "ham_train = group_train.get_group('ham')\n",
    "spam_train = group_train.get_group('spam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166c9f80-5319-4cc1-b390-494e35f0b093",
   "metadata": {},
   "source": [
    "#### Training set for ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9d3a09a-155d-4e06-9ceb-ce7b099ad4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set for ham: (7523, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>email_text</th>\n",
       "      <th>labeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>mailing list queried weeks ago running set arc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>greetings verify subscription plan fans list c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>quiet quiet well straw poll plan running</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>working departed totally bell labs recommended...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>greetings mass acknowledgement signed plan fan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                         email_text  labeling\n",
       "0    ham  mailing list queried weeks ago running set arc...         0\n",
       "3    ham  greetings verify subscription plan fans list c...         0\n",
       "5    ham           quiet quiet well straw poll plan running         0\n",
       "6    ham  working departed totally bell labs recommended...         0\n",
       "10   ham  greetings mass acknowledgement signed plan fan...         0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Size of training set for ham:\", ham_train.shape)\n",
    "ham_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b40581-bdb3-4594-be9c-3a14b0572004",
   "metadata": {},
   "source": [
    "#### Training set for spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "482e7655-6d11-4e30-b6e2-b2ccd56217c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set for spam: (13777, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>email_text</th>\n",
       "      <th>labeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>luxury watches buy rolex rolex cartier bvlgari...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>academic qualifications prestigious acc redite...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>guyton sheena will help mortgage loan loan see...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spam</td>\n",
       "      <td>nbc today body diet beaches magazines hollywoo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>oil sector going crazy weekly gift kkpt thing ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                         email_text  labeling\n",
       "1  spam  luxury watches buy rolex rolex cartier bvlgari...         1\n",
       "2  spam  academic qualifications prestigious acc redite...         1\n",
       "4  spam  guyton sheena will help mortgage loan loan see...         1\n",
       "7  spam  nbc today body diet beaches magazines hollywoo...         1\n",
       "8  spam  oil sector going crazy weekly gift kkpt thing ...         1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Size of training set for spam:\", spam_train.shape)\n",
    "spam_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d0f161-7c01-46ee-9981-5ded933f7f95",
   "metadata": {},
   "source": [
    "#### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6bb37873-d650-458f-82c8-45e0bd3b4e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of testing set: (16522, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>email_text</th>\n",
       "      <th>labeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21300</th>\n",
       "      <td>spam</td>\n",
       "      <td>ba df bc bc ba fc dd bf cc bd dd de ba bf bd d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21301</th>\n",
       "      <td>ham</td>\n",
       "      <td>things perform experiment display will remain ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21302</th>\n",
       "      <td>spam</td>\n",
       "      <td>best offer month viggra ci ialis vaiium xa naa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21303</th>\n",
       "      <td>spam</td>\n",
       "      <td>de ar wne cr doesn matter ow real st mmed ia t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21304</th>\n",
       "      <td>spam</td>\n",
       "      <td>ds body font size px color font family verdana...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                         email_text  labeling\n",
       "21300  spam  ba df bc bc ba fc dd bf cc bd dd de ba bf bd d...         1\n",
       "21301   ham  things perform experiment display will remain ...         0\n",
       "21302  spam  best offer month viggra ci ialis vaiium xa naa...         1\n",
       "21303  spam  de ar wne cr doesn matter ow real st mmed ia t...         1\n",
       "21304  spam  ds body font size px color font family verdana...         1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Size of testing set:\", test_set.shape)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50bd62e-e568-44df-a354-be17fc24d817",
   "metadata": {},
   "source": [
    "### Creating the feature matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31670223-75a4-4adb-9036-54de6c42cc91",
   "metadata": {},
   "source": [
    "#### Extracting a list of unique words from the training set along with its summed number of occurrences from the spam and ham set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5649277b-8095-433c-a4ba-37c901607772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating vocabulary dictionary for training set\n",
    "def vocabulary(data):\n",
    "    vocabulary = {}\n",
    "    for mail in data:\n",
    "        tokens = mail.split()\n",
    "        for word in tokens:\n",
    "            if word not in vocabulary:\n",
    "                vocabulary[word] = 1\n",
    "            else:\n",
    "                vocabulary[word]+=1\n",
    "    \n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d7b85746-2487-41ab-9c17-380d2bc462d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ee', 41277),\n",
       " ('px', 25271),\n",
       " ('eb', 15313),\n",
       " ('ea', 15052),\n",
       " ('ec', 14128),\n",
       " ('http', 13817),\n",
       " ('will', 12355),\n",
       " ('font', 11780),\n",
       " ('ef', 11706),\n",
       " ('padding', 10820),\n",
       " ('product', 9329),\n",
       " ('fb', 8633),\n",
       " ('table', 7649),\n",
       " ('border', 6934),\n",
       " ('weight', 6843),\n",
       " ('text', 6497),\n",
       " ('top', 6477),\n",
       " ('size', 6440),\n",
       " ('info', 6399),\n",
       " ('price', 6361),\n",
       " ('fc', 6184),\n",
       " ('pc', 6176),\n",
       " ('cc', 6098),\n",
       " ('color', 5975),\n",
       " ('company', 5706),\n",
       " ('ce', 5589),\n",
       " ('board', 5531),\n",
       " ('left', 5407),\n",
       " ('cf', 5079),\n",
       " ('cd', 5030),\n",
       " ('message', 4660),\n",
       " ('ba', 4656),\n",
       " ('gold', 4557),\n",
       " ('mail', 4460),\n",
       " ('crust', 4426),\n",
       " ('help', 4383),\n",
       " ('time', 4363),\n",
       " ('bd', 4306),\n",
       " ('bottom', 4111),\n",
       " ('list', 4006),\n",
       " ('ad', 3915),\n",
       " ('nil', 3823),\n",
       " ('content', 3818),\n",
       " ('bf', 3735),\n",
       " ('dqo', 3732),\n",
       " ('bnmzzs', 3719),\n",
       " ('send', 3704),\n",
       " ('subject', 3675),\n",
       " ('don', 3625),\n",
       " ('de', 3558),\n",
       " ('margin', 3540),\n",
       " ('medium', 3538),\n",
       " ('aa', 3531),\n",
       " ('bc', 3395),\n",
       " ('campaign', 3365),\n",
       " ('bb', 3360),\n",
       " ('work', 3347),\n",
       " ('website', 3293),\n",
       " ('china', 3208),\n",
       " ('program', 3128),\n",
       " ('received', 3108),\n",
       " ('af', 3104),\n",
       " ('align', 3042),\n",
       " ('compacted', 3025),\n",
       " ('handyboard', 3012),\n",
       " ('windows', 2964),\n",
       " ('vims', 2948),\n",
       " ('email', 2864),\n",
       " ('hb', 2848),\n",
       " ('stock', 2806),\n",
       " ('solid', 2804),\n",
       " ('normal', 2760),\n",
       " ('ve', 2755),\n",
       " ('type', 2744),\n",
       " ('bold', 2683),\n",
       " ('women', 2681),\n",
       " ('wrote', 2662),\n",
       " ('well', 2639),\n",
       " ('dc', 2634),\n",
       " ('good', 2624),\n",
       " ('ddd', 2596),\n",
       " ('number', 2556),\n",
       " ('net', 2528),\n",
       " ('problem', 2520),\n",
       " ('bit', 2515),\n",
       " ('cb', 2497),\n",
       " ('university', 2493),\n",
       " ('version', 2476),\n",
       " ('fe', 2463),\n",
       " ('plain', 2448),\n",
       " ('ic', 2411),\n",
       " ('news', 2392),\n",
       " ('html', 2381),\n",
       " ('opt', 2376),\n",
       " ('file', 2360),\n",
       " ('adobe', 2356),\n",
       " ('body', 2340),\n",
       " ('microsoft', 2327),\n",
       " ('day', 2323),\n",
       " ('office', 2296),\n",
       " ('energy', 2284),\n",
       " ('background', 2266),\n",
       " ('center', 2251),\n",
       " ('rating', 2212),\n",
       " ('ly', 2208),\n",
       " ('current', 2206),\n",
       " ('people', 2186),\n",
       " ('corp', 2175),\n",
       " ('best', 2154),\n",
       " ('reply', 2142),\n",
       " ('sp', 2126),\n",
       " ('ll', 2105),\n",
       " ('design', 2103),\n",
       " ('wo', 2101),\n",
       " ('jb', 2097),\n",
       " ('unicode', 2093),\n",
       " ('sb', 2090),\n",
       " ('add', 2080),\n",
       " ('code', 2073),\n",
       " ('dha', 2066),\n",
       " ('effects', 2040),\n",
       " ('main', 2038),\n",
       " ('width', 2035),\n",
       " ('studies', 2035),\n",
       " ('today', 2024),\n",
       " ('ac', 2019),\n",
       " ('imh', 1970),\n",
       " ('development', 1969),\n",
       " ('hoodia', 1968),\n",
       " ('data', 1942),\n",
       " ('awq', 1940),\n",
       " ('professional', 1934),\n",
       " ('ms', 1923),\n",
       " ('free', 1919),\n",
       " ('find', 1918),\n",
       " ('display', 1909),\n",
       " ('great', 1907),\n",
       " ('system', 1900),\n",
       " ('charset', 1891),\n",
       " ('fax', 1889),\n",
       " ('handy', 1886),\n",
       " ('read', 1875),\n",
       " ('market', 1874),\n",
       " ('da', 1862),\n",
       " ('dd', 1860),\n",
       " ('fd', 1854),\n",
       " ('mm', 1850),\n",
       " ('motor', 1845),\n",
       " ('tl', 1838),\n",
       " ('web', 1836),\n",
       " ('iahr', 1819),\n",
       " ('set', 1815),\n",
       " ('side', 1815),\n",
       " ('address', 1803),\n",
       " ('ab', 1801),\n",
       " ('site', 1791),\n",
       " ('vertical', 1791),\n",
       " ('save', 1790),\n",
       " ('power', 1790),\n",
       " ('jp', 1760),\n",
       " ('cdovl', 1748),\n",
       " ('call', 1743),\n",
       " ('org', 1723),\n",
       " ('usd', 1701),\n",
       " ('mime', 1695),\n",
       " ('bhttp', 1693),\n",
       " ('awr', 1680),\n",
       " ('mit', 1674),\n",
       " ('lkdgg', 1652),\n",
       " ('week', 1649),\n",
       " ('media', 1645),\n",
       " ('aw', 1642),\n",
       " ('vd', 1640),\n",
       " ('big', 1637),\n",
       " ('yahoo', 1633),\n",
       " ('days', 1632),\n",
       " ('hp', 1625),\n",
       " ('fx', 1625),\n",
       " ('high', 1620),\n",
       " ('full', 1615),\n",
       " ('offer', 1596),\n",
       " ('transfer', 1590),\n",
       " ('software', 1587),\n",
       " ('bring', 1587),\n",
       " ('life', 1584),\n",
       " ('oil', 1579),\n",
       " ('control', 1566),\n",
       " ('bg', 1555),\n",
       " ('zlaw', 1548),\n",
       " ('description', 1546),\n",
       " ('better', 1517),\n",
       " ('xp', 1515),\n",
       " ('port', 1513),\n",
       " ('space', 1510),\n",
       " ('block', 1505),\n",
       " ('family', 1490),\n",
       " ('subscribe', 1489),\n",
       " ('encoding', 1488),\n",
       " ('gas', 1479),\n",
       " ('money', 1472),\n",
       " ('ascii', 1461),\n",
       " ('fast', 1459),\n",
       " ('additional', 1451),\n",
       " ('long', 1438),\n",
       " ('based', 1438),\n",
       " ('reviews', 1436),\n",
       " ('years', 1423),\n",
       " ('decoration', 1422),\n",
       " ('computer', 1413),\n",
       " ('apple', 1402),\n",
       " ('visit', 1401),\n",
       " ('majordomo', 1399),\n",
       " ('myxnoaw', 1398),\n",
       " ('start', 1388),\n",
       " ('forward', 1386),\n",
       " ('wag', 1385),\n",
       " ('retail', 1380),\n",
       " ('complete', 1377),\n",
       " ('dg', 1372),\n",
       " ('service', 1369),\n",
       " ('hpb', 1366),\n",
       " ('small', 1356),\n",
       " ('fa', 1354),\n",
       " ('ra', 1347),\n",
       " ('fff', 1325),\n",
       " ('bm', 1318),\n",
       " ('robot', 1316),\n",
       " ('provide', 1311),\n",
       " ('cart', 1304),\n",
       " ('order', 1299),\n",
       " ('cs', 1299),\n",
       " ('img', 1297),\n",
       " ('currently', 1295),\n",
       " ('sender', 1293),\n",
       " ('technology', 1279),\n",
       " ('business', 1279),\n",
       " ('ae', 1273),\n",
       " ('experience', 1265),\n",
       " ('serial', 1264),\n",
       " ('hc', 1263),\n",
       " ('potential', 1263),\n",
       " ('project', 1235),\n",
       " ('messages', 1232),\n",
       " ('real', 1229),\n",
       " ('memory', 1227),\n",
       " ('check', 1224),\n",
       " ('starship', 1219),\n",
       " ('urd', 1216),\n",
       " ('post', 1213),\n",
       " ('pounds', 1206),\n",
       " ('pm', 1202),\n",
       " ('nl', 1201),\n",
       " ('special', 1193),\n",
       " ('exploration', 1192),\n",
       " ('problems', 1189),\n",
       " ('sans', 1187),\n",
       " ('account', 1184),\n",
       " ('aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa',\n",
       "  1180),\n",
       " ('original', 1178),\n",
       " ('going', 1174),\n",
       " ('digital', 1172),\n",
       " ('dy', 1169),\n",
       " ('verdana', 1162),\n",
       " ('thu', 1158),\n",
       " ('cantex', 1154),\n",
       " ('plan', 1152),\n",
       " ('receive', 1150),\n",
       " ('things', 1144),\n",
       " ('uk', 1143),\n",
       " ('serif', 1136),\n",
       " ('motors', 1135),\n",
       " ('df', 1133),\n",
       " ('question', 1133),\n",
       " ('low', 1122),\n",
       " ('report', 1121),\n",
       " ('range', 1118),\n",
       " ('format', 1115),\n",
       " ('international', 1108),\n",
       " ('class', 1107),\n",
       " ('thing', 1101),\n",
       " ('return', 1101),\n",
       " ('works', 1100),\n",
       " ('ephedra', 1099),\n",
       " ('support', 1096),\n",
       " ('online', 1088),\n",
       " ('php', 1080),\n",
       " ('legal', 1078),\n",
       " ('write', 1078),\n",
       " ('times', 1078),\n",
       " ('fn', 1078),\n",
       " ('hours', 1077),\n",
       " ('st', 1075),\n",
       " ('uy', 1074),\n",
       " ('loss', 1072),\n",
       " ('hyaku', 1072),\n",
       " ('tada', 1072),\n",
       " ('contact', 1066),\n",
       " ('image', 1061),\n",
       " ('dear', 1058),\n",
       " ('doesn', 1056),\n",
       " ('bgu', 1054),\n",
       " ('pine', 1048),\n",
       " ('expansion', 1047),\n",
       " ('files', 1046),\n",
       " ('ir', 1044),\n",
       " ('working', 1042),\n",
       " ('mon', 1042),\n",
       " ('approved', 1037),\n",
       " ('department', 1036),\n",
       " ('download', 1036),\n",
       " ('year', 1034),\n",
       " ('yew', 1034),\n",
       " ('htm', 1031),\n",
       " ('video', 1029),\n",
       " ('tue', 1029),\n",
       " ('servo', 1027),\n",
       " ('delivery', 1024),\n",
       " ('sep', 1022),\n",
       " ('point', 1020),\n",
       " ('science', 1019),\n",
       " ('change', 1015),\n",
       " ('apr', 1008),\n",
       " ('natural', 1001),\n",
       " ('short', 997),\n",
       " ('nob', 995),\n",
       " ('aug', 993),\n",
       " ('interested', 991),\n",
       " ('ewt', 989),\n",
       " ('jul', 983),\n",
       " ('jkzxi', 982),\n",
       " ('second', 978),\n",
       " ('output', 975),\n",
       " ('su', 971),\n",
       " ('iso', 966),\n",
       " ('products', 963),\n",
       " ('error', 961),\n",
       " ('infinex', 956),\n",
       " ('jeff', 954),\n",
       " ('sonar', 951),\n",
       " ('food', 949),\n",
       " ('questions', 948),\n",
       " ('running', 945),\n",
       " ('dragon', 945),\n",
       " ('td', 945),\n",
       " ('input', 945),\n",
       " ('dr', 945),\n",
       " ('place', 941),\n",
       " ('auto', 936),\n",
       " ('md', 935),\n",
       " ('fri', 932),\n",
       " ('lists', 927),\n",
       " ('fs', 923),\n",
       " ('access', 921),\n",
       " ('future', 920),\n",
       " ('growth', 917),\n",
       " ('fred', 917),\n",
       " ('claims', 913),\n",
       " ('properties', 911),\n",
       " ('test', 910),\n",
       " ('technologies', 906),\n",
       " ('mass', 904),\n",
       " ('internet', 902),\n",
       " ('light', 901),\n",
       " ('phone', 901),\n",
       " ('golden', 898),\n",
       " ('application', 896),\n",
       " ('zipping', 894),\n",
       " ('commands', 890),\n",
       " ('sensor', 890),\n",
       " ('leave', 889),\n",
       " ('services', 888),\n",
       " ('visited', 884),\n",
       " ('students', 882),\n",
       " ('ds', 880),\n",
       " ('vc', 879),\n",
       " ('cont', 878),\n",
       " ('collapse', 876),\n",
       " ('investors', 874),\n",
       " ('form', 870),\n",
       " ('release', 869),\n",
       " ('note', 868),\n",
       " ('include', 866),\n",
       " ('cubg', 866),\n",
       " ('greylink', 864),\n",
       " ('professionaladobe', 864),\n",
       " ('proms', 864),\n",
       " ('group', 863),\n",
       " ('aol', 861),\n",
       " ('three', 860),\n",
       " ('tel', 858),\n",
       " ('programs', 852),\n",
       " ('love', 852),\n",
       " ('en', 851),\n",
       " ('course', 848),\n",
       " ('including', 846),\n",
       " ('battery', 846),\n",
       " ('hello', 845),\n",
       " ('smtp', 842),\n",
       " ('esmtp', 839),\n",
       " ('mar', 837),\n",
       " ('db', 836),\n",
       " ('fine', 834),\n",
       " ('analog', 833),\n",
       " ('os', 831),\n",
       " ('sun', 830),\n",
       " ('uoregon', 830),\n",
       " ('mzc', 829),\n",
       " ('hope', 825),\n",
       " ('mode', 822),\n",
       " ('turn', 821),\n",
       " ('feel', 819),\n",
       " ('store', 818),\n",
       " ('lose', 818),\n",
       " ('systems', 816),\n",
       " ('case', 815),\n",
       " ('process', 813),\n",
       " ('int', 810),\n",
       " ('standard', 809),\n",
       " ('ncjxurcb', 808),\n",
       " ('pin', 803),\n",
       " ('limited', 799),\n",
       " ('cgdc', 798),\n",
       " ('oszhbxa', 796),\n",
       " ('idea', 794),\n",
       " ('watch', 794),\n",
       " ('pleased', 792),\n",
       " ('uuj', 791),\n",
       " ('san', 788),\n",
       " ('kind', 788),\n",
       " ('chip', 785),\n",
       " ('al', 784),\n",
       " ('archive', 780),\n",
       " ('common', 780),\n",
       " ('pdt', 779),\n",
       " ('prices', 773),\n",
       " ('zag', 771),\n",
       " ('ma', 766),\n",
       " ('corporation', 765),\n",
       " ('lcd', 764),\n",
       " ('opportunities', 761),\n",
       " ('znzc', 761),\n",
       " ('fh', 761),\n",
       " ('promotional', 760),\n",
       " ('committee', 759),\n",
       " ('repjwvvfi', 756),\n",
       " ('starting', 755),\n",
       " ('zwluzmfzaglvbi', 750),\n",
       " ('kpfrspg', 750),\n",
       " ('ncjxuuj', 750),\n",
       " ('bld', 749),\n",
       " ('press', 749),\n",
       " ('statements', 745),\n",
       " ('ck', 744),\n",
       " ('voltage', 743),\n",
       " ('update', 743),\n",
       " ('happy', 743),\n",
       " ('longer', 739),\n",
       " ('source', 739),\n",
       " ('john', 736),\n",
       " ('share', 736),\n",
       " ('simply', 736),\n",
       " ('huge', 735),\n",
       " ('buy', 734),\n",
       " ('dtzw', 734),\n",
       " ('bhdgg', 734),\n",
       " ('pro', 733),\n",
       " ('title', 732),\n",
       " ('edt', 729),\n",
       " ('white', 728),\n",
       " ('friday', 721),\n",
       " ('option', 720),\n",
       " ('agreement', 718),\n",
       " ('ag', 718),\n",
       " ('cm', 717),\n",
       " ('companies', 716),\n",
       " ('path', 716),\n",
       " ('america', 715),\n",
       " ('large', 714),\n",
       " ('lot', 707),\n",
       " ('archives', 706),\n",
       " ('prospect', 706),\n",
       " ('example', 705),\n",
       " ('link', 704),\n",
       " ('rolex', 702),\n",
       " ('bo', 702),\n",
       " ('cost', 698),\n",
       " ('drive', 698),\n",
       " ('dmdx', 698),\n",
       " ('production', 697),\n",
       " ('owner', 697),\n",
       " ('ha', 697),\n",
       " ('joint', 696),\n",
       " ('med', 696),\n",
       " ('qsbocmvmpsjodhrwoi', 693),\n",
       " ('waha', 692),\n",
       " ('lbnvpzd', 692),\n",
       " ('term', 691),\n",
       " ('shares', 689),\n",
       " ('lmxvdmvpbmzhc', 688),\n",
       " ('sell', 687),\n",
       " ('depression', 686),\n",
       " ('satisfaction', 685),\n",
       " ('credit', 684),\n",
       " ('led', 682),\n",
       " ('pcode', 682),\n",
       " ('ago', 680),\n",
       " ('shipping', 680),\n",
       " ('seismic', 680),\n",
       " ('field', 679),\n",
       " ('sensors', 676),\n",
       " ('agaa', 675),\n",
       " ('men', 674),\n",
       " ('vfi', 672),\n",
       " ('click', 670),\n",
       " ('opportunity', 669),\n",
       " ('required', 669),\n",
       " ('word', 668),\n",
       " ('ulmnvbs', 666),\n",
       " ('wrong', 665),\n",
       " ('ventures', 664),\n",
       " ('middle', 663),\n",
       " ('bob', 662),\n",
       " ('investment', 662),\n",
       " ('mtc', 660),\n",
       " ('discreet', 659),\n",
       " ('wx', 659),\n",
       " ('book', 657),\n",
       " ('issue', 657),\n",
       " ('lib', 656),\n",
       " ('mailing', 655),\n",
       " ('general', 655),\n",
       " ('private', 654),\n",
       " ('student', 654),\n",
       " ('minutes', 653),\n",
       " ('hard', 652),\n",
       " ('talk', 651),\n",
       " ('ready', 651),\n",
       " ('ub', 649),\n",
       " ('answer', 648),\n",
       " ('nj', 646),\n",
       " ('effective', 646),\n",
       " ('allow', 645),\n",
       " ('monday', 645),\n",
       " ('launch', 645),\n",
       " ('building', 643),\n",
       " ('hungry', 643),\n",
       " ('matter', 642),\n",
       " ('live', 642),\n",
       " ('public', 641),\n",
       " ('photoshop', 641),\n",
       " ('mike', 641),\n",
       " ('april', 640),\n",
       " ('split', 640),\n",
       " ('designed', 640),\n",
       " ('sincerely', 640),\n",
       " ('simple', 638),\n",
       " ('house', 638),\n",
       " ('user', 637),\n",
       " ('nov', 636),\n",
       " ('otkmyw', 634),\n",
       " ('discussion', 633),\n",
       " ('thought', 632),\n",
       " ('engineering', 631),\n",
       " ('interest', 630),\n",
       " ('worked', 630),\n",
       " ('solution', 630),\n",
       " ('third', 629),\n",
       " ('trade', 628),\n",
       " ('asked', 627),\n",
       " ('advance', 627),\n",
       " ('request', 626),\n",
       " ('zd', 626),\n",
       " ('announces', 625),\n",
       " ('record', 625),\n",
       " ('jan', 625),\n",
       " ('usa', 624),\n",
       " ('true', 623),\n",
       " ('customer', 622),\n",
       " ('abgd', 622),\n",
       " ('wire', 618),\n",
       " ('school', 617),\n",
       " ('details', 616),\n",
       " ('fact', 616),\n",
       " ('play', 614),\n",
       " ('ev', 614),\n",
       " ('hvcf', 614),\n",
       " ('ii', 613),\n",
       " ('sleep', 612),\n",
       " ('shareholder', 612),\n",
       " ('watches', 611),\n",
       " ('pg', 611),\n",
       " ('ij', 611),\n",
       " ('la', 611),\n",
       " ('north', 608),\n",
       " ('localhost', 608),\n",
       " ('te', 608),\n",
       " ('language', 607),\n",
       " ('device', 607),\n",
       " ('fall', 607),\n",
       " ('characters', 607),\n",
       " ('build', 605),\n",
       " ('character', 605),\n",
       " ('connected', 605),\n",
       " ('server', 603),\n",
       " ('function', 603),\n",
       " ('box', 603),\n",
       " ('reading', 602),\n",
       " ('history', 601),\n",
       " ('easy', 601),\n",
       " ('lines', 600),\n",
       " ('jjpsjodhrwoi', 600),\n",
       " ('pj', 600),\n",
       " ('directly', 599),\n",
       " ('degree', 597),\n",
       " ('management', 597),\n",
       " ('texas', 597),\n",
       " ('canyon', 597),\n",
       " ('interface', 597),\n",
       " ('connect', 595),\n",
       " ('area', 595),\n",
       " ('gps', 595),\n",
       " ('library', 594),\n",
       " ('ph', 593),\n",
       " ('local', 593),\n",
       " ('american', 592),\n",
       " ('mineral', 592),\n",
       " ('eat', 592),\n",
       " ('machine', 589),\n",
       " ('offers', 589),\n",
       " ('aqaqaaaajgypabya', 589),\n",
       " ('buying', 588),\n",
       " ('signal', 586),\n",
       " ('extension', 586),\n",
       " ('speed', 586),\n",
       " ('mac', 585),\n",
       " ('afgd', 584),\n",
       " ('independent', 583),\n",
       " ('sunbird', 582),\n",
       " ('dec', 581),\n",
       " ('loan', 580),\n",
       " ('marketing', 580),\n",
       " ('increase', 578),\n",
       " ('open', 577),\n",
       " ('numbers', 577),\n",
       " ('acrobat', 576),\n",
       " ('conference', 576),\n",
       " ('water', 576),\n",
       " ('robotics', 576),\n",
       " ('refresh', 575),\n",
       " ('nbsp', 574),\n",
       " ('edition', 572),\n",
       " ('total', 570),\n",
       " ('vm', 570),\n",
       " ('pure', 569),\n",
       " ('level', 569),\n",
       " ('uz', 569),\n",
       " ('president', 567),\n",
       " ('mining', 567),\n",
       " ('manager', 567),\n",
       " ('swath', 566),\n",
       " ('choice', 564),\n",
       " ('started', 564),\n",
       " ('cash', 563),\n",
       " ('bl', 563),\n",
       " ('deal', 562),\n",
       " ('processing', 560),\n",
       " ('remember', 560),\n",
       " ('bad', 559),\n",
       " ('nzk', 558),\n",
       " ('quality', 557),\n",
       " ('weeks', 556),\n",
       " ('engaged', 556),\n",
       " ('circuit', 556),\n",
       " ('result', 556),\n",
       " ('west', 553),\n",
       " ('position', 552),\n",
       " ('resources', 549),\n",
       " ('developing', 549),\n",
       " ('making', 549),\n",
       " ('fully', 549),\n",
       " ('response', 548),\n",
       " ('rzpg', 547),\n",
       " ('ns', 546),\n",
       " ('xnjmuy', 546),\n",
       " ('expect', 545),\n",
       " ('hair', 545),\n",
       " ('linux', 545),\n",
       " ('bhy', 544),\n",
       " ('mcbozwlnahq', 544),\n",
       " ('premiere', 542),\n",
       " ('ig', 542),\n",
       " ('move', 541),\n",
       " ('fat', 541),\n",
       " ('desire', 539),\n",
       " ('pt', 539),\n",
       " ('babaaaaambg', 538),\n",
       " ('organic', 536),\n",
       " ('turned', 535),\n",
       " ('paper', 535),\n",
       " ('mb', 535),\n",
       " ('close', 535),\n",
       " ('zl', 535),\n",
       " ('minerals', 534),\n",
       " ('pretty', 532),\n",
       " ('called', 531),\n",
       " ('man', 531),\n",
       " ('country', 531),\n",
       " ('hot', 531),\n",
       " ('length', 529),\n",
       " ('odd', 528),\n",
       " ('heart', 528),\n",
       " ('em', 527),\n",
       " ('meeting', 527),\n",
       " ('members', 526),\n",
       " ('haven', 526),\n",
       " ('operations', 526),\n",
       " ('stahl', 526),\n",
       " ('baaaac', 525),\n",
       " ('sharp', 524),\n",
       " ('located', 522),\n",
       " ('june', 521),\n",
       " ('cpu', 519),\n",
       " ('wpg', 518),\n",
       " ('peegahjlzj', 518),\n",
       " ('bank', 517),\n",
       " ('projects', 517),\n",
       " ('major', 515),\n",
       " ('won', 515),\n",
       " ('load', 513),\n",
       " ('reference', 512),\n",
       " ('cn', 512),\n",
       " ('network', 511),\n",
       " ('producer', 510),\n",
       " ('month', 510),\n",
       " ('held', 510),\n",
       " ('communication', 510),\n",
       " ('greko', 510),\n",
       " ('dvd', 509),\n",
       " ('maximize', 509),\n",
       " ('gmt', 509),\n",
       " ('mt', 509),\n",
       " ('person', 508),\n",
       " ('college', 508),\n",
       " ('stress', 507),\n",
       " ('ap', 506),\n",
       " ('luck', 506),\n",
       " ('umtyzlmnvbs', 506),\n",
       " ('island', 505),\n",
       " ('supply', 505),\n",
       " ('multi', 504),\n",
       " ('ide', 504),\n",
       " ('lang', 503),\n",
       " ('hw', 502),\n",
       " ('url', 502),\n",
       " ('correct', 502),\n",
       " ('yzgvypta', 502),\n",
       " ('muscle', 501),\n",
       " ('math', 501),\n",
       " ('gp', 499),\n",
       " ('servos', 499),\n",
       " ('reports', 498),\n",
       " ('applications', 498),\n",
       " ('millions', 498),\n",
       " ('bt', 498),\n",
       " ('soft', 498),\n",
       " ('mental', 497),\n",
       " ('industry', 497),\n",
       " ('needed', 497),\n",
       " ('errors', 494),\n",
       " ('pzd', 494),\n",
       " ('lego', 494),\n",
       " ('rid', 493),\n",
       " ('multiple', 493),\n",
       " ('didn', 493),\n",
       " ('proprietary', 492),\n",
       " ('luzz', 492),\n",
       " ('columbia', 492),\n",
       " ('card', 491),\n",
       " ('parts', 491),\n",
       " ('attention', 490),\n",
       " ('early', 490),\n",
       " ('entire', 490),\n",
       " ('bbb', 490),\n",
       " ('driver', 490),\n",
       " ('zw', 489),\n",
       " ('highly', 487),\n",
       " ('el', 486),\n",
       " ('oizhbxa', 486),\n",
       " ('shareholders', 485),\n",
       " ('job', 484),\n",
       " ('advice', 484),\n",
       " ('focus', 484),\n",
       " ('books', 484),\n",
       " ('announced', 483),\n",
       " ('risk', 483),\n",
       " ('key', 483),\n",
       " ('stuff', 483),\n",
       " ('issues', 483),\n",
       " ('interesting', 482),\n",
       " ('wrinkles', 482),\n",
       " ('div', 481),\n",
       " ('mhz', 481),\n",
       " ('mood', 480),\n",
       " ('tech', 480),\n",
       " ('consider', 479),\n",
       " ('es', 479),\n",
       " ('south', 477),\n",
       " ('sex', 477),\n",
       " ('cwtd', 476),\n",
       " ('expected', 475),\n",
       " ('appreciated', 475),\n",
       " ('directors', 475),\n",
       " ('green', 474),\n",
       " ('bwvudwlkptm', 474),\n",
       " ('copy', 473),\n",
       " ('antonio', 473),\n",
       " ('item', 472),\n",
       " ('pay', 472),\n",
       " ('martin', 472),\n",
       " ('venture', 471),\n",
       " ('ovc', 470),\n",
       " ('knowledge', 469),\n",
       " ('diet', 469),\n",
       " ('ports', 469),\n",
       " ('tenure', 468),\n",
       " ('uqk', 468),\n",
       " ('vcghvdg', 468),\n",
       " ('rested', 467),\n",
       " ('nx', 467),\n",
       " ('nail', 466),\n",
       " ('awake', 466),\n",
       " ('qwxpz', 466),\n",
       " ('weaeaaaacygdwawap', 466),\n",
       " ('zwluzmfzaglvbm', 466),\n",
       " ('director', 465),\n",
       " ('suggestions', 465),\n",
       " ('fatigue', 464),\n",
       " ('customers', 464),\n",
       " ('cr', 464),\n",
       " ('unix', 463),\n",
       " ('soundly', 463),\n",
       " ('global', 463),\n",
       " ('interactive', 463),\n",
       " ('unit', 462),\n",
       " ('est', 462),\n",
       " ('ability', 461),\n",
       " ('sat', 461),\n",
       " ('included', 461),\n",
       " ('aid', 461),\n",
       " ('xnzy', 460),\n",
       " ('room', 459),\n",
       " ('au', 458),\n",
       " ('hardware', 458),\n",
       " ('ncjxuqk', 458),\n",
       " ('bk', 458),\n",
       " ('lean', 457),\n",
       " ('rk', 457),\n",
       " ('rest', 456),\n",
       " ('rate', 455),\n",
       " ('programming', 455),\n",
       " ('names', 455),\n",
       " ('aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa',\n",
       "  455),\n",
       " ('verified', 454),\n",
       " ('volume', 454),\n",
       " ('wmm', 454),\n",
       " ('ccc', 453),\n",
       " ('screen', 453),\n",
       " ('securities', 453),\n",
       " ('jonathan', 453),\n",
       " ('command', 452),\n",
       " ('model', 452),\n",
       " ('tuesday', 452),\n",
       " ('rvlje', 452),\n",
       " ('understand', 451),\n",
       " ('yw', 451),\n",
       " ('written', 450),\n",
       " ('lmnvbs', 450),\n",
       " ('mx', 450),\n",
       " ('sector', 449),\n",
       " ('underline', 449),\n",
       " ('single', 449),\n",
       " ('sags', 448),\n",
       " ('charge', 448),\n",
       " ('wondering', 448),\n",
       " ('mz', 448),\n",
       " ('revitalizes', 447),\n",
       " ('friend', 447),\n",
       " ('orgasms', 447),\n",
       " ('ross', 447),\n",
       " ('red', 447),\n",
       " ('nevada', 446),\n",
       " ('manual', 446),\n",
       " ('win', 446),\n",
       " ('august', 445),\n",
       " ('ib', 445),\n",
       " ('coming', 445),\n",
       " ('pill', 444),\n",
       " ('drilling', 443),\n",
       " ('encore', 443),\n",
       " ('epo', 443),\n",
       " ('health', 442),\n",
       " ('pr', 441),\n",
       " ('changed', 441),\n",
       " ('bestsellers', 441),\n",
       " ('combination', 441),\n",
       " ('arizona', 440),\n",
       " ('kpfrct', 440),\n",
       " ('darkwing', 440),\n",
       " ('mailer', 438),\n",
       " ('rct', 438),\n",
       " ('ftp', 437),\n",
       " ('ps', 437),\n",
       " ('nt', 437),\n",
       " ('pins', 437),\n",
       " ('register', 436),\n",
       " ('national', 436),\n",
       " ('institute', 434),\n",
       " ('series', 434),\n",
       " ('changes', 433),\n",
       " ('pa', 433),\n",
       " ('titlelink', 432),\n",
       " ('mediadescription', 432),\n",
       " ('nowrap', 432),\n",
       " ('addtolist', 432),\n",
       " ('dgts', 432),\n",
       " ('collectionadobe', 432),\n",
       " ('audition', 432),\n",
       " ('proadobe', 432),\n",
       " ('trace', 432),\n",
       " ('match', 432),\n",
       " ('july', 432),\n",
       " ('bn', 432),\n",
       " ('vsbfnwywnpbmc', 432),\n",
       " ('search', 431),\n",
       " ('thinking', 430),\n",
       " ('david', 430),\n",
       " ('groups', 429),\n",
       " ('team', 428),\n",
       " ('fighting', 428),\n",
       " ('papers', 428),\n",
       " ('par', 428),\n",
       " ('suif', 428),\n",
       " ('clixme', 426),\n",
       " ('vefcteugy', 426),\n",
       " ('root', 425),\n",
       " ('safely', 424),\n",
       " ('exciting', 424),\n",
       " ('unique', 424),\n",
       " ('ideas', 423),\n",
       " ('remove', 422),\n",
       " ('letter', 422),\n",
       " ('higher', 421),\n",
       " ('difficult', 421),\n",
       " ('humans', 421),\n",
       " ('wd', 421),\n",
       " ('create', 420),\n",
       " ('cable', 420),\n",
       " ('jmftcdtjcgf', 420),\n",
       " ('personal', 419),\n",
       " ('style', 419),\n",
       " ('grows', 418),\n",
       " ('graduate', 418),\n",
       " ('vzmzlci', 418),\n",
       " ('nb', 417),\n",
       " ('tv', 417),\n",
       " ('wc', 416),\n",
       " ('security', 414),\n",
       " ('val', 414),\n",
       " ('ywlslnbocd', 414),\n",
       " ('nh', 413),\n",
       " ('rzpjwvvefcteu', 412),\n",
       " ('formula', 412),\n",
       " ('java', 411),\n",
       " ('texada', 410),\n",
       " ('cialis', 410),\n",
       " ('inform', 408),\n",
       " ('continue', 407),\n",
       " ('aaaabaaaac', 407),\n",
       " ('ebay', 406),\n",
       " ('writes', 405),\n",
       " ('rf', 405),\n",
       " ('franklin', 405),\n",
       " ('max', 405),\n",
       " ('se', 403),\n",
       " ('allows', 403),\n",
       " ('il', 402),\n",
       " ('repg', 402),\n",
       " ('frank', 401),\n",
       " ('truth', 401),\n",
       " ('directory', 401),\n",
       " ('consumer', 401),\n",
       " ('couple', 401),\n",
       " ('trading', 400),\n",
       " ('ctxe', 400),\n",
       " ('reason', 398),\n",
       " ('base', 398),\n",
       " ('lm', 398),\n",
       " ('xvdmvpbmzhc', 398),\n",
       " ('literally', 397),\n",
       " ('wasn', 397),\n",
       " ...]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = vocabulary(train_set['email_text'])\n",
    "# sort the dictionary according to the top 10,000 words\n",
    "most_common_word = sorted(vocab.items(), key=lambda x:-x[1])[:10000]\n",
    "most_common_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d199f017-c8de-4d9c-8bc1-a87eefe802c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_matrix(emails, most_common_word):\n",
    "    emails = emails.tolist()\n",
    "    feature_vectors = []\n",
    "    \n",
    "    # count the occurrence of words per email and store it in a vector\n",
    "    for mail in emails:\n",
    "        # Tokenize the email into words\n",
    "        words = mail.split()\n",
    "    \n",
    "        # initializing a vector of zeros having the same length as the most_common_word(10000)\n",
    "        email_vector = [0]*len(most_common_word)\n",
    "        \n",
    "        # Iterate through each word in the email\n",
    "        for word in words:\n",
    "            if word in most_common_word:\n",
    "                # Find the index of the word in the vocabulary\n",
    "                word_index = list(most_common_word.index(word))\n",
    "                # Increment the corresponding element of the vector\n",
    "                email_vector[word_index] += 1\n",
    "                \n",
    "        # Append the feature vector of the email to the feature matrix\n",
    "        feature_vectors.append(email_vector)\n",
    "    return feature_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe20ed58-4162-4c11-a0a4-91d7889c9194",
   "metadata": {},
   "source": [
    "#### Feature matrix for spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1349275d-65a0-4473-b204-b5839846cc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_feature_matrix = np.array(count_matrix(spam_train['email_text'], most_common_word))\n",
    "spam_feature_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87379c01-b272-4fd8-b6cc-fba916a144f1",
   "metadata": {},
   "source": [
    "#### Feature matrix for ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "26b5bbbf-ee8d-4aa5-b80a-e7836bbf15ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_feature_matrix = np.array(count_matrix(ham_train['email_text'], most_common_word))\n",
    "ham_feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1c7b3787-52b2-46cd-bae1-97dd7251fe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion to compute for prior probabilities of spam and ham\n",
    "def prior_probabilities(label_count, email_count):\n",
    "    prob = label_count/email_count\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bbe5d5cf-18fc-45bb-b090-1216c69f0b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior probabilities for spam:  0.6468075117370892\n",
      "Prior probabilities for ham:  0.3531924882629108\n"
     ]
    }
   ],
   "source": [
    "# Getting the count of ham and spam emails and the total count of email in the training set\n",
    "ham_count = len(ham_train)\n",
    "spam_count = len(spam_train)\n",
    "email_count = len(train_set)\n",
    "\n",
    "# probability of spam\n",
    "prior_spam = prior_probabilities(spam_count, email_count)\n",
    "print(\"Prior probabilities for spam: \", prior_spam)\n",
    "\n",
    "# probability of ham\n",
    "prior_ham = prior_probabilities(ham_count, email_count)\n",
    "print(\"Prior probabilities for ham: \", prior_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6719dd1-d1a9-44bb-a38d-6e2ffc341ad5",
   "metadata": {},
   "source": [
    "### Computing the Likelihood of each word (15 points + 5 points for Laplace smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "357ee300-d1b3-4e6a-ab5a-508e89b570d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_smoothing(most_common_word, train_set, vocab):\n",
    "    likelihood_vector = np.zeros(len(most_common_word))\n",
    "    word_count = vocabulary(train_set) \n",
    "    total_word_count = sum(word_count.values()) # total number of words in spam/ham\n",
    "\n",
    "    # Defining the smoothing parameter k\n",
    "    k = 1\n",
    "    word_freq = 0\n",
    "    for i in range(len(most_common_word)): \n",
    "        word = most_common_word[i][0]\n",
    "        # if the word does not appear in the word_count dictionary, put 0 \n",
    "        if word not in word_count:\n",
    "            word_count[word] = 0\n",
    "        else:\n",
    "            word_freq = word_count[word]  # number of times the word appears in word_count(spam or ham) dictionary\n",
    "\n",
    "        # computing for the likelihoods\n",
    "        # P(word1|spam) = (count of word1 belonging to category spam/ham + k)/(total count of words belonging to spam/ham + no of distinct words in training data)\n",
    "        likelihood_vector[i] = (word_freq + k)/(total_word_count + k*len(vocab))\n",
    "    return likelihood_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712348a4-1f9e-4a74-99e6-66e55cf99695",
   "metadata": {},
   "source": [
    "#### Computing the probability of each word for ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4f1af8bd-36a7-4ed7-ac87-e2b883719b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.51694651e-04, 4.56426383e-05, 5.77245131e-05, ...,\n",
       "       1.74515970e-05, 1.74515970e-05, 1.74515970e-05])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_likelihood_vector = laplace_smoothing(most_common_word, ham_train['email_text'], vocab)\n",
    "ham_likelihood_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e26a3af-b4e0-424e-8373-5ca2912af5ef",
   "metadata": {},
   "source": [
    "#### Computing the probability of each word form spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d572ddc3-52cb-4c55-8786-eb49b1ff9781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.57458540e-02, 1.58069873e-02, 9.55066890e-03, ...,\n",
       "       5.64423272e-06, 5.64423272e-06, 5.64423272e-06])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_likelihood_vector = laplace_smoothing(most_common_word, spam_train['email_text'], vocab)\n",
    "spam_likelihood_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec5528f-5a67-40f1-9b21-6e985ae410d5",
   "metadata": {},
   "source": [
    "### Classifying the emails (10 points + 10 points for computing the log probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "73ee1331-29de-4c1e-aea7-62f72899a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_classification(emails, most_common_word, ham_likelihood_vector, spam_likelihood_vector, prior_ham, prior_spam):\n",
    "    #list that will hold the predictions\n",
    "    prediction = []                               \n",
    "    dic_features = dict(most_common_word)\n",
    "    #list of features based on the most common word\n",
    "    list_features = list(dic_features.keys())     \n",
    "    \n",
    "    # Iterate over emails in the dataset\n",
    "    for mail in emails:\n",
    "        # Initialize the variables\n",
    "        prob_ham = 0\n",
    "        prob_spam = 0\n",
    "        # create tokens\n",
    "        tokens = str(mail).split()\n",
    "        for token in tokens:\n",
    "            if token in list_features:\n",
    "                # adding the likelihoods\n",
    "                index_no = list_features.index(token)\n",
    "                l_ham = ham_likelihood_vector[index_no]\n",
    "                l_spam = spam_likelihood_vector[index_no]\n",
    "                prob_ham += np.log(l_ham)\n",
    "                prob_spam += np.log(l_spam)\n",
    "        # adding the prior probabilities\n",
    "        prob_ham+=np.log(prior_ham)\n",
    "        prob_spam+=np.log(prior_spam)\n",
    "        \n",
    "        # find the classifier with the higher probability\n",
    "        if prob_ham > prob_spam:\n",
    "            classification = 0    #spam\n",
    "            prediction.append(classification)\n",
    "        elif prob_spam > prob_ham:\n",
    "            classification = 1    #ham\n",
    "            prediction.append(classification)\n",
    "            \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ab31dc55-af36-40ec-a105-1975f3b33ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kurt Matthew Amodia\\AppData\\Local\\Temp\\ipykernel_10200\\1648564358.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set['prediction'] = prediction_train\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>email_text</th>\n",
       "      <th>labeling</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>mailing list queried weeks ago running set arc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>luxury watches buy rolex rolex cartier bvlgari...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>academic qualifications prestigious acc redite...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>greetings verify subscription plan fans list c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>guyton sheena will help mortgage loan loan see...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>quiet quiet well straw poll plan running</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>working departed totally bell labs recommended...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spam</td>\n",
       "      <td>nbc today body diet beaches magazines hollywoo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>oil sector going crazy weekly gift kkpt thing ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>magic perfect weekends http othxu rzfzwiwwfoeh...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                         email_text  labeling  \\\n",
       "0   ham  mailing list queried weeks ago running set arc...         0   \n",
       "1  spam  luxury watches buy rolex rolex cartier bvlgari...         1   \n",
       "2  spam  academic qualifications prestigious acc redite...         1   \n",
       "3   ham  greetings verify subscription plan fans list c...         0   \n",
       "4  spam  guyton sheena will help mortgage loan loan see...         1   \n",
       "5   ham           quiet quiet well straw poll plan running         0   \n",
       "6   ham  working departed totally bell labs recommended...         0   \n",
       "7  spam  nbc today body diet beaches magazines hollywoo...         1   \n",
       "8  spam  oil sector going crazy weekly gift kkpt thing ...         1   \n",
       "9  spam  magic perfect weekends http othxu rzfzwiwwfoeh...         1   \n",
       "\n",
       "   prediction  \n",
       "0           0  \n",
       "1           1  \n",
       "2           1  \n",
       "3           0  \n",
       "4           1  \n",
       "5           0  \n",
       "6           0  \n",
       "7           1  \n",
       "8           1  \n",
       "9           1  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction of the model using train set\n",
    "prediction_train = email_classification(train_set['email_text'], most_common_word, ham_likelihood_vector, spam_likelihood_vector, prior_ham, prior_spam)\n",
    "\n",
    "# add a prediction column to the training set\n",
    "train_set['prediction'] = prediction_train\n",
    "train_set.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00209d97-6139-468d-8913-a1b6b68096a8",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "10421a21-b4fc-433f-8ee1-d53bcb26f854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kurt Matthew Amodia\\AppData\\Local\\Temp\\ipykernel_10200\\2267060349.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set['prediction'] = prediction_test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>email_text</th>\n",
       "      <th>labeling</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21300</th>\n",
       "      <td>spam</td>\n",
       "      <td>ba df bc bc ba fc dd bf cc bd dd de ba bf bd d...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21301</th>\n",
       "      <td>ham</td>\n",
       "      <td>things perform experiment display will remain ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21302</th>\n",
       "      <td>spam</td>\n",
       "      <td>best offer month viggra ci ialis vaiium xa naa...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21303</th>\n",
       "      <td>spam</td>\n",
       "      <td>de ar wne cr doesn matter ow real st mmed ia t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21304</th>\n",
       "      <td>spam</td>\n",
       "      <td>ds body font size px color font family verdana...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21305</th>\n",
       "      <td>spam</td>\n",
       "      <td>multi message mime format dragon content type ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21306</th>\n",
       "      <td>spam</td>\n",
       "      <td>delarosa alyssa will feeling happy med product...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21307</th>\n",
       "      <td>spam</td>\n",
       "      <td>mistersporty incorporation rambrantplein ad de...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21308</th>\n",
       "      <td>spam</td>\n",
       "      <td>choice best choice drugs viagra pill viagra so...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21309</th>\n",
       "      <td>ham</td>\n",
       "      <td>ve changed dmdx listserv subject filter hopefu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                         email_text  labeling  \\\n",
       "21300  spam  ba df bc bc ba fc dd bf cc bd dd de ba bf bd d...         1   \n",
       "21301   ham  things perform experiment display will remain ...         0   \n",
       "21302  spam  best offer month viggra ci ialis vaiium xa naa...         1   \n",
       "21303  spam  de ar wne cr doesn matter ow real st mmed ia t...         1   \n",
       "21304  spam  ds body font size px color font family verdana...         1   \n",
       "21305  spam  multi message mime format dragon content type ...         1   \n",
       "21306  spam  delarosa alyssa will feeling happy med product...         1   \n",
       "21307  spam  mistersporty incorporation rambrantplein ad de...         1   \n",
       "21308  spam  choice best choice drugs viagra pill viagra so...         1   \n",
       "21309   ham  ve changed dmdx listserv subject filter hopefu...         0   \n",
       "\n",
       "       prediction  \n",
       "21300           1  \n",
       "21301           0  \n",
       "21302           1  \n",
       "21303           1  \n",
       "21304           1  \n",
       "21305           1  \n",
       "21306           1  \n",
       "21307           1  \n",
       "21308           1  \n",
       "21309           0  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_test = email_classification(test_set['email_text'], most_common_word, ham_likelihood_vector, spam_likelihood_vector, prior_ham, prior_spam)\n",
    "# add a prediction column to the testing set\n",
    "test_set['prediction'] = prediction_test\n",
    "test_set.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9723307c-1c37-4e70-ae3e-5d149401b891",
   "metadata": {},
   "source": [
    "### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "eae7003b-5948-4597-bc5d-2456b9ef40d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9208328289553322\n",
      "Recall:  0.9110911540188594\n",
      "Precision:  0.9696071872311957\n",
      "Confusion Matrix:\n",
      " [[ 5069   318]\n",
      " [  990 10145]]\n"
     ]
    }
   ],
   "source": [
    "# using sci-kit learn\n",
    "y_test = np.array(test_set['labeling'])\n",
    "y_pred = np.array(test_set['prediction'])\n",
    "\n",
    "# Evaluate using accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "# Evaluate using recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Recall: \", recall)\n",
    "\n",
    "# Evaluate using precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precision: \", precision)\n",
    "\n",
    "# Evaluation using confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f57ecaf-bd70-43e8-9405-a2075b1598b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
